{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a309ddc",
   "metadata": {},
   "source": [
    "# About\n",
    "This notebook describes how centers were chosen for classifying activity in the BBP circuit. The github repo \"Tribal Dynamics\" (located at https://github.com/JasonPSmith/TriDy) is necessary to execute some of the cells in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eecca9d",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237b160",
   "metadata": {},
   "source": [
    "## Step 1: Compute parameters\n",
    "To choose the desired centers, parameter values must be computed at all the centers of the circuit. This is done in the external file `compute_parameters.py`, which is executed several times by the commands show below. These commands also appear in the file `compute_parameters.sh`. The resulting files are stored in the folder `parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ab280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python compute_parameters.py spectral\n",
    "# python compute_parameters.py spectral_reverse\n",
    "# python compute_parameters.py simplices\n",
    "# python compute_parameters.py degrees\n",
    "# python compute_parameters.py cc\n",
    "# python compute_parameters.py dc\n",
    "# python compute_parameters.py nbc\n",
    "# python compute_parameters.py rc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c7e8d",
   "metadata": {},
   "source": [
    "Density paramaters are computed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = np.load('parameters/rc.npy')\n",
    "simp0 = np.load('parameters/simp0.npy')\n",
    "simp1 = np.load('parameters/simp1.npy')\n",
    "\n",
    "# Reciprocal connections per nodes\n",
    "rcpn = rc/simp0\n",
    "np.save('parameters/rcpn.npy',rcpn)\n",
    "\n",
    "# Reciprocal connections per edges\n",
    "rcpe = rc/simp1\n",
    "np.save('parameters/rcpe.npy',rcpe)\n",
    "\n",
    "# Edges per nodes\n",
    "epn = simp1/simp0\n",
    "np.save('parameters/epn.npy',epn)\n",
    "\n",
    "# The number of nodes in a neighbourhood is called `tribe_size` for legacy reasons\n",
    "tribe_size = np.copy(simp0)\n",
    "np.save('parameters/tribe_size.npy',tribe_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e97d29",
   "metadata": {},
   "source": [
    "## Step 2: Set up containers for centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the excitatory-excitatory subcircuit (number of neurons)\n",
    "nnum = 26567\n",
    "\n",
    "# Number of neighborhoods to be used in classifying activity\n",
    "number_nbhds = 50\n",
    "\n",
    "# Percentage of centers to consider when sampling by density\n",
    "density_cutoff = 0.01\n",
    "cutoff_size = int(nnum*density_cutoff)\n",
    "\n",
    "# Dictionary for holding center indices\n",
    "data_dict = {'first_selection':[], 'second_selection':[], 'first_selection_order':[], 'second_selection_order':[]}\n",
    "for i in range(number_nbhds):\n",
    "        data_dict['chief'+str(i)] = []\n",
    "        \n",
    "# Computed parameters\n",
    "filenames = [f for f in listdir('parameters/') if isfile(join('parameters/', f))]\n",
    "paramnames = [f.split('.')[0] for f in filenames if f[-4:] == '.npy']\n",
    "paramdata = {f:np.load('parameters/'+f+'.npy') for f in paramnames}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00136365",
   "metadata": {},
   "source": [
    "## Step 3.1: Random choices from the excitatory-excitatory subcircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271791a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random selections    \n",
    "choice_num = 4\n",
    "print(f\"Recording {choice_num} random groups of {number_nbhds}\",flush=True)\n",
    "\n",
    "for c in range(choice_num):\n",
    "    data_dict['first_selection'].append(f\"random{c}\")\n",
    "    data_dict['second_selection'].append(np.nan)\n",
    "    data_dict['first_selection_order'].append(np.nan)\n",
    "    data_dict['second_selection_order'].append(np.nan)\n",
    "    current_indices = np.random.choice(range(nnum), size=number_nbhds, replace=False)\n",
    "    for i in range(number_nbhds):\n",
    "        data_dict['chief'+str(i)].append(current_indices[i])\n",
    "        \n",
    "print('All done', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdea628",
   "metadata": {},
   "source": [
    "## Step 3.2: Random choices among the 1% sparsest and 1% densest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1bd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random selections from 1% sparsest     \n",
    "choice_num = 4\n",
    "print(f\"Recording {choice_num} random groups of {number_nbhds} from sparsest {density_cutoff}\",flush=True)\n",
    "\n",
    "values = np.argsort(rcpn)[:cutoff_size]\n",
    "for c in range(choice_num):\n",
    "    data_dict['first_selection'].append(f\"sparse_random{c}\")\n",
    "    data_dict['second_selection'].append(np.nan)\n",
    "    data_dict['first_selection_order'].append(np.nan)\n",
    "    data_dict['second_selection_order'].append(np.nan)\n",
    "    current_indices = np.random.choice(values, size=number_nbhds, replace=False)\n",
    "    for i in range(number_nbhds):\n",
    "        data_dict['chief'+str(i)].append(current_indices[i])\n",
    "\n",
    "# Random selections from 1% densest     \n",
    "choice_num = 4\n",
    "print(f\"Recording {choice_num} random groups of {number_nbhds} from densest {density_cutoff}\",flush=True)\n",
    "\n",
    "values = np.argsort(rcpn)[-cutoff_size:]\n",
    "for c in range(choice_num):\n",
    "    data_dict['first_selection'].append(f\"dense_random{c}\")\n",
    "    data_dict['second_selection'].append(np.nan)\n",
    "    data_dict['first_selection_order'].append(np.nan)\n",
    "    data_dict['second_selection_order'].append(np.nan)\n",
    "    current_indices = np.random.choice(values, size=number_nbhds, replace=False)\n",
    "    for i in range(number_nbhds):\n",
    "        data_dict['chief'+str(i)].append(current_indices[i])\n",
    "        \n",
    "print('All done', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6a3ae",
   "metadata": {},
   "source": [
    "## Step 3.3: Single selection for all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every parameter, bottom value\n",
    "print('Recording bottom values for all parameters', flush=True)\n",
    "for p in paramnames:\n",
    "    data_dict['first_selection'].append(p)\n",
    "    data_dict['second_selection'].append(np.nan)\n",
    "    data_dict['first_selection_order'].append('bottom')\n",
    "    data_dict['second_selection_order'].append(np.nan)\n",
    "    selection = np.argsort(paramdata[p])\n",
    "    for i in range(number_nbhds):\n",
    "        data_dict['chief'+str(i)].append(selection[i])\n",
    "            \n",
    "# Every parameter, top value\n",
    "print('Recording top values for all parameters', flush=True)\n",
    "for p in paramnames:\n",
    "    data_dict['first_selection'].append(p)\n",
    "    data_dict['second_selection'].append(np.nan)\n",
    "    data_dict['first_selection_order'].append('top')\n",
    "    data_dict['second_selection_order'].append(np.nan)\n",
    "    selection = [x for _, x in sorted(zip(paramdata[p], range(nnum)))][::-1]\n",
    "    for i in range(number_nbhds):\n",
    "        data_dict['chief'+str(i)].append(selection[i])\n",
    "\n",
    "print('All done', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef2db9",
   "metadata": {},
   "source": [
    "## Step 3.4: Double selection for all parameters\n",
    "Restrict to the sparsest (then densest) 1% of neighbourhoods in the excitatory-excitatory subcircuit, then from that 1% select centers by their parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double selection after restricting to sparsest neighbourhoods\n",
    "print(f\"Recording bottom and top values for all parameters, from sparsest {density_cutoff}\", flush=True)\n",
    "double_choices = np.argsort(paramdata['rc_per_nodes'])[:cutoff_size]\n",
    "\n",
    "for p in paramnames:\n",
    "    if p != 'rc_per_nodes':\n",
    "        selection = [x for _, x in sorted(zip(paramdata[p][double_choices], double_choices))]\n",
    "        \n",
    "        # Bottom\n",
    "        data_dict['first_selection'].append('rc_per_nodes')\n",
    "        data_dict['second_selection'].append(p)\n",
    "        data_dict['first_selection_order'].append('sparse')\n",
    "        data_dict['second_selection_order'].append('bottom')\n",
    "        for i in range(number_nbhds):\n",
    "            data_dict['chief'+str(i)].append(selection[i])\n",
    "        \n",
    "        # Top\n",
    "        data_dict['first_selection'].append(first_selection)\n",
    "        data_dict['second_selection'].append(p)\n",
    "        data_dict['first_selection_order'].append('sparse')\n",
    "        data_dict['selection_order'].append('top')\n",
    "        for i in range(number_nbhds):\n",
    "            data_dict['chief'+str(i)].append(selection[::-1][i])\n",
    "            \n",
    "# Double selection after restricting to densest neighbourhoods\n",
    "print(f\"Recording bottom and top values for all parameters, from densest {density_cutoff}\", flush=True)\n",
    "double_choices = np.argsort(paramdata['rc_per_nodes'])[-cutoff_size:]\n",
    "\n",
    "for p in paramnames:\n",
    "    if p != 'rc_per_nodes':\n",
    "        selection = [x for _, x in sorted(zip(paramdata[p][double_choices], double_choices))]\n",
    "        \n",
    "        # Bottom\n",
    "        data_dict['first_selection'].append('rc_per_nodes')\n",
    "        data_dict['second_selection'].append(p)\n",
    "        data_dict['first_selection_order'].append('dense')\n",
    "        data_dict['second_selection_order'].append('bottom')\n",
    "        for i in range(number_nbhds):\n",
    "            data_dict['chief'+str(i)].append(selection[i])\n",
    "        \n",
    "        # Top\n",
    "        data_dict['first_selection'].append(first_selection)\n",
    "        data_dict['second_selection'].append(p)\n",
    "        data_dict['first_selection_order'].append('dense')\n",
    "        data_dict['selection_order'].append('top')\n",
    "        for i in range(number_nbhds):\n",
    "            data_dict['chief'+str(i)].append(selection[::-1][i])\n",
    "            \n",
    "print('All done', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae3525c",
   "metadata": {},
   "source": [
    "## Step 4: Export final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "\n",
    "# Export dataframe\n",
    "df.to_pickle('selections.pkl')\n",
    "\n",
    "# Export ragged array for TriDy-tools\n",
    "partition = []\n",
    "for i in range(df.shape[0]):\n",
    "    current = []\n",
    "    for j in range(number_nbhds):\n",
    "        current.append(exc_loc[df.iloc[i]['chief'+str(j)]])\n",
    "    partition.append(current)\n",
    "np.save('TriDy-tools/bins/partition_reliability.npy', np.array(partition))\n",
    "\n",
    "print('All done', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
