{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline for reliability bootstrapping based on block-design-based simulation campaigns\n",
    "1. Extract & cut spike trains\n",
    "2. Compute filtered spike signals & mean-centering\n",
    "3. Compute firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract & cut spike trains\n",
    "\n",
    "Extracts (excitatory) spike trains in format compatible with \"toposample\" pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract import run_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/home/pokorny/BbpWorkflowKernel/lib/python3.9/site-packages/tables/file.py:411: UserWarning: a closed node found in the registry: ``/neuron_info/meta/values_block_3/meta/_i_table``\n",
      "  warnings.warn(\"a closed node found in the registry: \"\n",
      "/gpfs/bbp.cscs.ch/ssd/apps/bsd/2022-01-10/stage_applications/install_gcc-11.2.0-skylake/py-numpy-1.19.5-gjm7kk/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 90 spike files written to \"/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/bbp_workflow/e41d95a2-0e94-4e9a-9898-e0ea1497edf0/working_dir\"\n"
     ]
    }
   ],
   "source": [
    "campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/BlobStimReliability_O1v5-SONATA_OutConnsRemoved_BlockDesign_Struct'\n",
    "# campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/BlobStimReliability_O1v5-SONATA_OutConnsRemoved_BlockDesign_Rnd'\n",
    "# campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/BlobStimReliability_O1v5-SONATA_RecipConnsRemoved_BlockDesign_Struct'\n",
    "# campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/BlobStimReliability_O1v5-SONATA_RecipConnsRemoved_BlockDesign_Rnd'\n",
    "\n",
    "sim_paths, working_dir = run_extraction(campaign_path, working_dir_name='working_dir')\n",
    "num_sims = len(sim_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute filtered spike signals & mean-centering\n",
    "\n",
    "Runs preprocessing (filtering, mean-centering) of (excitatory) spike trains [PARALLEL IMPLEMENTATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import run_preprocessing, merge_into_h5_data_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing in 852.391s\n"
     ]
    }
   ],
   "source": [
    "# Run preprocessing\n",
    "spike_file_names = [f'raw_spikes_exc_{idx}.npy' for idx in range(num_sims)]\n",
    "\n",
    "run_preprocessing(working_dir, spike_file_names, sigma=10.0, mean_centered=True, pool_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge individual preprocessed spike files into .h5 data store\n",
    "#   split_by_gid==False ... Datasets per sim\n",
    "#   split_by_gid==True  ... Datasets per sim & GID\n",
    "tmp_file_names = [f'spike_signals_exc_{idx}__tmp__.npz' for idx in range(num_sims)]\n",
    "\n",
    "h5_file = merge_into_h5_data_store(working_dir, tmp_file_names, data_store_name='processed_data_store', split_by_gid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute firing rates\n",
    "\n",
    "Runs firing rate extraction based on mean inverse inter-spike interval of (excitatory) spike trains [PARALLEL IMPLEMENTATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import run_rate_extraction, merge_rates_to_h5_data_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run rate extraction\n",
    "spike_file_names = [f'raw_spikes_exc_{idx}.npy' for idx in range(num_sims)]\n",
    "\n",
    "run_rate_extraction(working_dir, spike_file_names, pool_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:01<00:00, 46.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 90 files merged and added to \"/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/bbp_workflow/6852a83f-3e7c-4705-b6cd-fe2a34bbfba2/working_dir/processed_data_store.h5\"\n"
     ]
    }
   ],
   "source": [
    "# Merge individual rate files into .h5 data store\n",
    "tmp_file_names = [f'firing_rates_exc_{idx}__tmp__.npz' for idx in range(num_sims)]\n",
    "\n",
    "h5_file = merge_rates_to_h5_data_store(working_dir, tmp_file_names, data_store_name='processed_data_store', do_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__HOW TO LOAD PROCESSED SPIKE SIGNALS, META-INFO, AND RATES FROM .H5 DATA STORE:__\n",
    "~~~\n",
    "h5_store = h5py.File(h5_file)\n",
    "print(f'Groups/Datasets: {list(h5_store.keys())}')\n",
    "t_bins = np.array(h5_store['t_bins'])\n",
    "gids = np.array(h5_store['gids'])\n",
    "firing_rates = np.array(h5_store['firing_rates'])\n",
    "mean_centered = np.array(h5_store['mean_centered']).tolist()\n",
    "sigma = np.array(h5_store['sigma']).tolist()\n",
    "print(f'Spike signals per sims: {list(h5_store[\"spike_signals_exc\"].keys())}')\n",
    "if split_by_gid == True:\n",
    "    print(f'Spike signals within sim <SIM_IDX>: {list(h5_store[\"spike_signals_exc\"][\"sim_<SIM_IDX>\"].keys())}')\n",
    "    spike_signal = np.array(h5_store['spike_signals_exc'][f'sim_{<SIM_IDX>}'][f'gid_{<GID>}'])\n",
    "else:\n",
    "    spike_signals = np.array(h5_store['spike_signals_exc'][f'sim_{<SIM_IDX>}'])\n",
    "h5_store.close()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BbpWorkflowKernel",
   "language": "python",
   "name": "bbpworkflowkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
