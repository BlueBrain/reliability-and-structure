{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of spike trains for TriDy/TopoSampling pipeline\n",
    "\n",
    "This notebook is used to prepare the spike trains obtained from simulations for classification using a neighborhood-based stimulus classification pipeline (TriDy/TopoSampling pipeline; see [`../../classification`](../../classification)). As opposed to reliabiliy simulations (short simulations, but multiple seeds) we assume here simulation campaigns with only one (long) simulation of a single seed.\n",
    "\n",
    "__Data preparation overview:__\n",
    "- Neuron info (mc2 target): __neuron_info.pickle__ (and __.h5__, nut not required by pipeline)\n",
    "- EXC spikes (mc2 target; EXC only): __raw_spikes_exc.npy__\n",
    "- Stimulus train: __stim_stream.npy__ (and __time_windows.npy__, but not required by pipeline)\n",
    "- Adjacency matrix (mc2 target; re-indexed): __connectivity.npz__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../library')\n",
    "from extract import run_extraction  # Requires bluepy kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir: \"toposample_input\" (EXC spike trains)\n"
     ]
    }
   ],
   "source": [
    "syn_class = 'EXC'\n",
    "\n",
    "output_dir_name = 'toposample_input'  # Default name\n",
    "print(f'Output dir: \"{output_dir_name}\" ({syn_class} spike trains)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/home/pokorny/BbpWorkflowKernel/lib/python3.9/site-packages/tables/file.py:411: UserWarning: a closed node found in the registry: ``/neuron_info/meta/values_block_3/meta/_i_table``\n",
      "  warnings.warn(\"a closed node found in the registry: \"\n",
      "/gpfs/bbp.cscs.ch/ssd/apps/bsd/2022-01-10/stage_applications/install_gcc-11.2.0-skylake/py-numpy-1.19.5-gjm7kk/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 1 spike files written to \"/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/bbp_workflow/e23aa485-8885-4e50-bd1f-9a9661463704/toposample_input\"\n"
     ]
    }
   ],
   "source": [
    "# BlueConfig campaigns\n",
    "# campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/Toposample_O1v5-SONATA'  # Baseline\n",
    "# campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/Toposample_O1v5-SONATA_ConnRewired_mc2EE_Order1'\n",
    "# campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/Toposample_O1v5-SONATA_ConnRewired_mc2EE_Order2'\n",
    "campaign_path = '/gpfs/bbp.cscs.ch/data/scratch/proj9/bisimplices/simulations/Toposample_O1v5-SONATA_ConnRewired_mc2EE_Order3'\n",
    "\n",
    "sim_paths, output_dir = run_extraction(campaign_path, working_dir_name=output_dir_name, syn_class=syn_class)\n",
    "num_sims = len(sim_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235133 spikes from 0.025ms to 159999.850ms\n",
      "\n",
      "8 patterns, 800 stimuli in total:\n",
      "  P0: 100, P1: 100, P2: 100, P3: 100, P4: 100, P5: 100, P6: 100, P7: 100\n"
     ]
    }
   ],
   "source": [
    "# Check if only one sim as expected; in this case we just rename the file and we are done!\n",
    "if num_sims == 1:\n",
    "    src_file = os.path.join(output_dir, 'raw_spikes_exc_0.npy')\n",
    "    tgt_file = os.path.join(output_dir, 'raw_spikes_exc.npy')\n",
    "    os.rename(src_file, tgt_file)\n",
    "\n",
    "    spk = np.load(tgt_file)\n",
    "    stim = np.load(os.path.join(output_dir, 'stim_stream.npy'))\n",
    "    print(f'{spk.shape[0]} spikes from {np.min(spk[:, 0]):.3f}ms to {np.max(spk[:, 0]):.3f}ms\\n')\n",
    "    print(f'{len(np.unique(stim))} patterns, {len(stim)} stimuli in total:')\n",
    "    print('  ' + ', '.join([f'P{_sid}: {_cnt}'  for _sid, _cnt in zip(*np.unique(stim, return_counts=True))]))\n",
    "else:\n",
    "    print(f'WARNING: {num_sims} spike files in campaign! Merging required into a single file!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BbpWorkflowKernel",
   "language": "python",
   "name": "bbpworkflowkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
